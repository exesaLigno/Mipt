#ifndef ASM
	#define ASM(nasm, byte, byte_length)
#endif

// ASM("", {}, 0)
// unsigned char test[] = {0x45, 0xc3, 0xff}; - correct usage

ASM("nop", {0x90}, 1)

ASM("mov rax, %d", {0xb8, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rbx, %d", {0xbb, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rcx, %d", {0xb9, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rdx, %d", {0xba, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rsi, %d", {0xbe, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rdi, %d", {0xbf, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rbp, %d", {0xbd, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov rsp, %d", {0xbc, 0x00, 0x00, 0x00, 0x00}, 5)
ASM("mov r8, %d", {0x41, 0xb8, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r9, %d", {0x41, 0xb9, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r10, %d", {0x41, 0xba, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r11, %d", {0x41, 0xbb, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r12, %d", {0x41, 0xbc, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r13, %d", {0x41, 0xbd, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r14, %d", {0x41, 0xbe, 0x00, 0x00, 0x00, 0x00}, 6)
ASM("mov r15, %d", {0x41, 0xbf, 0x00, 0x00, 0x00, 0x00}, 6)

ASM("push rax", {0x50}, 1)
ASM("push rbx", {0x53}, 1)
ASM("push rcx", {0x51}, 1)
ASM("push rdx", {0x52}, 1)
ASM("push rsi", {0x56}, 1)
ASM("push rdi", {0x57}, 1)
ASM("push rbp", {0x55}, 1)
ASM("push rsp", {0x54}, 1)
ASM("push r8", {0x41, 0x50}, 2)
ASM("push r9", {0x41, 0x51}, 2)
ASM("push r10", {0x41, 0x52}, 2)
ASM("push r11", {0x41, 0x53}, 2)
ASM("push r12", {0x41, 0x54}, 2)
ASM("push r13", {0x41, 0x55}, 2)
ASM("push r14", {0x41, 0x56}, 2)
ASM("push r15", {0x41, 0x57}, 2)

ASM("pop rax", {0x58}, 1)
ASM("pop rbx", {0x5b}, 1)
ASM("pop rcx", {0x59}, 1)
ASM("pop rdx", {0x5a}, 1)
ASM("pop rsi", {0x5e}, 1)
ASM("pop rdi", {0x5f}, 1)
ASM("pop rbp", {0x5d}, 1)
ASM("pop rsp", {0x5c}, 1)
ASM("pop r8", {0x41, 0x58}, 2)
ASM("pop r9", {0x41, 0x59}, 2)
ASM("pop r10", {0x41, 0x5a}, 2)
ASM("pop r11", {0x41, 0x5b}, 2)
ASM("pop r12", {0x41, 0x5c}, 2)
ASM("pop r13", {0x41, 0x5d}, 2)
ASM("pop r14", {0x41, 0x5e}, 2)
ASM("pop r15", {0x41, 0x5f}, 2)

ASM("mov cl, ah", {0x88, 0xe1}, 2)
ASM("mov dl, ah", {0x88, 0xe2}, 2)

ASM("and cl, 01000000b", {0x80, 0xe1, 0x40}, 3)
ASM("xor cl, 01000000b", {0x80, 0xf1, 0x40}, 3)

ASM("and cl, 10000000b", {0x80, 0xe1, 0x80}, 3)
ASM("xor cl, 10000000b", {0x80, 0xf1, 0x80}, 3)

ASM("and dl, 01000000b", {0x80, 0xe2, 0x40}, 3)
ASM("xor dl, 01000000b", {0x80, 0xf2, 0x40}, 3)

ASM("and dl, 10000000b", {0x80, 0xe2, 0x80}, 3)
ASM("xor dl, 10000000b", {0x80, 0xf2, 0x80}, 3)

ASM("mov r15, rsp", {0x49, 0x89, 0xe7}, 3)
ASM("mov r14, rsp", {0x49, 0x89, 0xe6}, 3)

ASM("sub rsp, %d", {0x48, 0x83, 0xec, 0x00}, 4)
ASM("add rsp, %d", {0x48, 0x83, 0xc4, 0x00}, 4)

ASM("mov rdi, rax", {0x48, 0x89, 0xc7}, 3)
ASM("syscall", {0x0f, 0x05}, 2)
ASM("ret", {0xc3}, 1)

ASM("test rax, rax", {0x48, 0x85, 0xc0}, 3)

ASM("add rax, rbx", {0x48, 0x01, 0xd8}, 3)
ASM("sub rax, rbx", {0x48, 0x29, 0xd8}, 3)
ASM("imul rbx", {0x48, 0xf7, 0xeb}, 3)
ASM("imul ebx", {0xf7, 0xeb}, 2)
ASM("idiv rbx", {0x48, 0xf7, 0xfb}, 3)

ASM("xor rcx, rcx", {0x48, 0x31, 0xc9}, 3)
ASM("xor rdx, rdx", {0x48, 0x31, 0xd2}, 3)

ASM("cmp rax, rbx", {0x48, 0x39, 0xd8}, 3)

ASM("lahf", {0x9f}, 1)


ASM("shr cl, 6", {0xc0, 0xe9, 0x06}, 3)
ASM("shr cl, 7", {0xc0, 0xe9, 0x07}, 3)

ASM("shr dl, 6", {0xc0, 0xea, 0x06}, 3)
ASM("shr dl, 7", {0xc0, 0xea, 0x07}, 3)

ASM("or rcx, rdx", {0x48, 0x09, 0xd1}, 3)
ASM("and rcx, rdx", {0x48, 0x21, 0xd1}, 3)

ASM("or rax, rbx", {0x48, 0x09, 0xd8}, 3)
ASM("and rax, rbx", {0x48, 0x21, 0xd8}, 3)

ASM("mov [rbx], rax", {0x48, 0x89, 0x03}, 3)

ASM("mov rax, r14", {0x4c, 0x89, 0xf0}, 3)

ASM("mov rax, r14", {0x4c, 0x89, 0xf0}, 3)
ASM("add rax, %d", {0x48, 0x83, 0xc0, 0x00}, 4)
ASM("mov rax, r15", {0x4c, 0x89, 0xf8}, 3)
ASM("mov rax, [r14 + %d]", {0x49, 0x8b, 0x46, 0x00}, 4)
ASM("mov rax, [r15 + %d]", {0x49, 0x8b, 0x47, 0x00}, 4)

//ASM("jz label			| 0f 84 .. .. .. ..
